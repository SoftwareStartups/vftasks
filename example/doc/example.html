<h2>Introduction</h2>
This document describes the examples that explain the vfTasks API:
<ul>
<li><a href="#workers">Worker thread pools</a>;</li>
<li><a href="#sync">2D task synchronization</a>;</li>
<li><a href="#channels">Streaming FIFO channels</a>.</li>
</ul>
Currently, these examples can only be run on a POSIX compliant system.
<p>This document does not aim to explain the principles and mechanisms of the vfTasks
API. Detailed documentation on this library can be found on the
<a href="http://www.vectorfabrics.com/static/documentation/vftasks" target="_blank">
documentation page</a>.</p>

<h2>Prerequisites</h2>
<ul>
<li>gcc 4.* (<a href="http://gcc.gnu.org" target="_blank">http://gcc.gnu.org/</a>)</li>
<li>POSIX thread library
(<a href="https://computing.llnl.gov/tutorials/pthreads" target="_blank">
https://computing.llnl.gov/tutorials/pthreads/</a>)</li>
</ul>


<h2><a name="workers">Worker thread pools</a></h2>
<p>The code in <code>loop.c</code> shows a simple data-parallel loop that will
be partitioned using the vfTasks worker thread pool.
By using the worker thread part of the vfTasks API, this loop
is partitioned and the work distributed over (parallel) worker threads.</p>

<h3>Building the example code</h3>
Build and run the reference (unpartitioned) example as follows:
<pre>
    $ gcc loop.c -o loop
    $ ./loop
PASSED
</pre>
Build and run the partitioned example as follows:
<pre>
    $ gcc partitioned_loop.c -pthread -I &lt;vftasks_install_path&gt;/include \
        -L &lt;vftasks_install_path&gt;/lib -lvftasks \
        -o partitioned_loop
    $ ./partitioned_loop
PASSED
</pre>


<h3>Creating a worker thread pool</h3>
<p>First of all, a worker pool needs to be created. In the case of vfTasks, the number of
workers needs to be equal to or larger than the number of tasks.
This implies that unlike in the standard worker thread design pattern
no task queue is used.</p>
<p>The example code divides the loop in 4 partitions. Therefore a pool of 3 workers
is created, because one partition is kept in the main thread:</p>
<pre>
    int main()
    {
      pool = vftasks_create_pool(3, 0);
      ...
      vftasks_destroy_pool(pool);
      ...
</pre>
<p>The second argument indicates whether busy-wait loops are used when waiting for
work to be submitted and waiting for work to be finished. When set to 0, these busy-wait
loops are replaced by a semaphore mechanism.</p>

<h3>Partition the loop over workers</h3>
<p>Since the worker threads only accept functions with signature
<code>void task(void *args)</code>,
the loop needs to be extracted into a function with this prototype. Some additional info
needs to be passed to the task: the loop partition start index and the loop partition length.
This additional info is packed in a struct that can be passed to the
<code>vftasks_submit</code> function:</p>
<pre>
    typedef struct
    {
      int start;
      int length;
    } args_t;
    ...
    for (k = 0; k &lt; N_PARTITIONS-1; k++)
    {
      args&#91;k&#93;.start = k * M / N_PARTITIONS;
      args&#91;k&#93;.length = M / N_PARTITIONS;
      rc |= vftasks_submit(pool, task, &amp;args&#91;k&#93;, 0);
    }

    args&#91;k&#93;.start = k * M / N_PARTITIONS;
    args&#91;k&#93;.length = M / N_PARTITIONS;
    task(&amp;args&#91;k&#93;);
</pre>
<p>Note that one partition is kept in the calling thread to prevent it from idling
and not waste thread resources. The partitioned loop iteration space now looks like this:</p>
<pre>
    for (i = args-&gt;start; i &lt; args-&gt;start + args-&gt;length; i++)
    {
      ...
</pre>

<h3>Waiting for task completion</h3>
<p>After submitting tasks to the workers, the <code>vftasks_get</code> function
can be used to wait for the workers to finish their tasks.<p>
<pre>
    vftasks_get(pool);
</pre>
<p>A call to this function will wait for the most recently submitted task to finish.</p>

<h2><a name="sync">2D task synchronization</a></h2>

<p>The code in <code>example/src/2d.c</code> shows operations in nested loops on a
2-dimensional array (<code>void go()</code>). Normally these nested loops could be easily
parallelized by distributing the work over a number of worker threads. However,
the branch in this loop:</p>
<pre>
    for (i = 0; i &lt; M; i++)
    {
      for (j = 0; j &lt; N; j++)
      {
        if (i &gt; 0 &amp;&amp; j + 1 &lt; N)
        {
          a&#91;i&#93;&#91;j&#93; = i * j + a&#91;i - 1&#93;&#91;j + 1&#93;; /* loop-carried dependency */
        }
        else
        {
          a&#91;i&#93;&#91;j&#93; = i * j;
        }
      }
    }
</pre>
<p>introduces a 2-dimensional loop-carried dependency that blocks straight-forward
data partitioning.</p>

<p>The vfTasks API offers a number of functions to account for synchronization
of these loop carried dependencies. These features will be explained using the code in
<code>example/src/2dsync.c</code>. This code is written by following a recipe that
has been generated by the
<a href="http://www.vectorfabrics.com/products/pareon" target="_blank">
Pareon</a> tool.

<h3>Building the example code</h3>
Build and run the reference (unpartitioned) example as follows:
<pre>
    $ gcc 2d.c -o 2d
    $ ./2d
PASSED
</pre>
Build and run the partitioned example as follows:
<pre>
    $ gcc 2dsync.c -pthread -I &lt;vftasks_install_path&gt;/include \
        -L &lt;vftasks_install_path&gt;/lib -lvftasks -o 2dsync
    $ ./2dsync
PASSED
</pre>

<h3>Creating a worker thread pool</h3>
<p>The creation of a worker thread pool is done in the same manner as explained
in the previous example.</p>

<h3>Partitioning the loop</h3>
<p>Because of the loop-carried dependency, the loop iteration space is partitioned
in a slightly different manner than in the previous example: instead of evenly
dividing the iteration spaces into chunks, a round-robin partitioning is applied
in order to prevent deadlocks. The loop iteration space now looks as follows:</p>

<pre>
    for (i = args-&gt;start; i &lt; M; i += args-&gt;stride)
    {
      ...
</pre>

<p>The submitting of tasks now looks slightly different:</p>
<pre>
    typedef struct
    {
      int start;
      int stride;
    } args_t;
    ...
    for (k = 0; k &lt; N_PARTITIONS-1; k++)
    {
      args&#91;k&#93;.start = k;
      args&#91;k&#93;.stride = N_PARTITIONS;
      vftasks_submit(pool, task, &amp;args&#91;k&#93;, 0);
    }

    args&#91;k&#93;.start = k;
    args&#91;k&#93;.stride = N_PARTITIONS;
    results&#91;k&#93; = task(&amp;args&#91;k&#93;);
</pre>


<p>After submitting all work, the calling task/thread will wait for the tasks to complete
by calling <code>vftasks_get</code> for each call to <code>vftasks_submit</code>.</p>

<h3>Synchronizing the loop-carried dependency</h3>
<p>In order to have a functionally correct example, the loop-carried dependency still
needs to be synchronized. The dependency</p>
<pre>
    a&#91;i&#93;&#91;j&#93; = i * j + a&#91;i - 1&#93;&#91;j + 1&#93;;
</pre>
means that the dependency's x-distance is 1 and the y-distance is -1. These values are
used to create a synchronization manager:
<pre>
    sync_mgr = vftasks_create_2d_sync_mgr(M, N, 1, -1);
</pre>
<p>where M and N are the iteration spaces (or array dimensions)
in x and y direction respectively.
This manager can then be used to wait for dependencies to be met and signal
that dependencies have been met:</p>
<pre>
    for (...)
    {
      for (...)
      {
        vftasks_wait_2d(sync_mgr, outer_loop_idx, inner_loop_idx);
        ...
        /* do the work (fulfill dependencies) */
        ...
        vftasks_signal_2d(sync_mgr, outer_loop_idx, inner_loop_idx);
      }
    }
</pre>

<p>This will cause the worker to block execution when a certain dependency
has not been met yet. A soon as this dependency has been met (typically in another
worker) this other worker will signal the blocked worker that it is safe to continue.</p>


<h2><a name="channels">Streaming FIFO's</a></h2>

<p>The <code>example/src/streams.c</code> contains an elementary functional partitioning
into two communicating tasks using POSIX threads. The reader and writer task communicate
through a FIFO channel using the vfTasks API.</p>

<h3>Building the example code</h3>

Build and run the example as follows:
<pre>
    $ gcc -pthread -I &lt;vftasks_install_path&gt;/include \
        -L &lt;vftasks_install_path&gt;/lib streams.c -lvftasks -o streams
    $ ./streams
PASSED: 100010000
</pre>

<h3>Writer and reader tasks</h3>

<p>The function <code>writer()</code> writes individual values (integers) to the
channel's write port <code>wport</code>. The writer takes a value from the
<code>writer_data</code> array, increments it by one using the <code>succ()</code>
function and writes it to the channel.</p>
<pre>
    for (i = 0; i &lt; PROBLEM_SIZE; ++i)
      vftasks_write_int32(wport, succ(writer_data&#91;i&#93;));
</pre>
<p>The <code>writer_data</code> is initialized by the <code>main()</code> function.</p>

<p>The <code>reader()</code> function reads these values from the channel's read port
and multiplies them by two using the <code>dbl()</code> function:</p>
<pre>
    for (i = 0; i &lt; PROBLEM_SIZE; ++i)
      reader_data&#91;i&#93; = dbl(vftasks_read_int32(rport));
</pre>
<p>The reader writes the resulting values to the <code>reader_data</code> array.</p>

<p>Apart from creating the reader and writer POSIX threads and creating the channel,
the <code>main()</code> function initializes the global <code>writer_data</code> array.
After both the writer and reader task are completed, it computes the sum of all values in
the global <code>reader_data</code> array:</p>
<pre>
    result = sum(reader_data);
</pre>

<h3>Channel setup</h3>

<p>The <code>main()</code> function creates the channel, its write and read ports.
The channel allows <code>FIFO_DEPTH</code> tokens, each of the size of one integer:</p>
<pre>
    chan = vftasks_create_chan(FIFO_DEPTH, sizeof(int), &amp;mem_mgr, &amp;mem_mgr);
    wport = vftasks_create_write_port(chan, &amp;mem_mgr);
    rport = vftasks_create_read_port(chan, &amp;mem_mgr);
</pre>
<p>Here, the <code>mem_mgr</code> sets hooks to allocate and free memory
for the channel and port structures. In a normal setup,
these hooks are set to the default libc functions
<code>malloc</code> and <code>free</code>. However, if your (embedded) processor does not
support these, the hooks allow you to implement your own memory management functions.</p>

<p>In order to suspend tasks waiting on room or data to become available in the channel,
we implement OS-specific hooks for suspending and resuming and set high and low water
marks top indicate when a task should be woken up:</p>
<pre>
    vftasks_install_chan_hooks(chan,
                               suspend_writer,
                               resume_writer,
                               suspend_reader,
                               resume_reader);
    vftasks_set_min_room(chan, LOW_WATER_MARK);
    vftasks_set_min_data(chan, HIGH_WATER_MARK);

    vftasks_set_channel_info(chan, &amp;info);
</pre>
<p>Here, we install the <code>suspend_writer</code> hook to suspend a (writer) task that
writes to a write port on the channel when there is no room available for writing in the
channel. When there is at least <code>LOW_WATER_MARK</code> room available, the
<code>resume_writer</code> hook is called to resume the writer.
Similarly, the <code>suspend_reader</code> suspends a (reader) task that reads from a
read port on the channel when there is no data available for reading.
When there is at least <code>HIGH_WATER_MARK</code> data available,
the <code>resume_reader</code> hook is called to resume the reader.</p>

<p>To implement suspend and resume functions, we add application-specific data to the
channel in the <code>info</code> struct to hold the necessary mutex and condition
variables. The implementation of e.g. <code>suspend_reader()</code> using the POSIX
thread API is roughly as follows:</p>
<pre>
    info = vftasks_get_chan_info(vftasks_chan_of_rport(rport));
    pthread_mutex_lock(&amp;info-&gt;mutex);
    if (!vftasks_data_available(rport)) {
        pthread_cond_wait(&amp;info->cond, &amp;info-&gt;mutex);
    }
    pthread_mutex_unlock(&amp;info-&gt;mutex);
</pre>
<p>The check for available data to read from the channel and the suspend
(<code>pthread_cond_wait()</code>) call are guarded with a mutex to avoid race conditions
when e.g. the writer writes data into an empty channel just after the check on available
data (<code>vftasks_data_available()</code>) but before the thread is suspended
(<code>pthread_cond_wait()</code>).</p>

<p>In a similar fashion, the <code>resume_reader</code> wakes up the tasks waiting on the
<code>info-&gt;cond</code> condition via the <code>phtread_cond_broadcast()</code>
call:</p>
<pre>
    info = vftasks_get_chan_info(vftasks_chan_of_rport(rport));
    pthread_mutex_lock(&amp;info-&gt;mutex);
    pthread_cond_broadcast(&amp;info-&gt;cond, &amp;info-&gt;mutex);
    pthread_mutex_unlock(&amp;info-&gt;mutex);
</pre>
<p>The mutex and condition are stored in the channel <code>info</code> struct so that the
resume/suspend for both the reader and writer can access these and the variables are
dedicated per channel.</p>
